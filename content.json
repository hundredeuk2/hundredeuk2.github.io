{"pages":[],"posts":[{"title":"블로그 개설","text":"나만의 블로그 개설!!21년 새로운 목표 그리고 나의 자기개발과 성실성을 증가시키기 위함을 목적으로 만든 블로그이다. 아직 매우 미숙하고 블로그 자체도 제데로 만들어져있지 않지만 이렇게 게시글을 올리는 행동으로 계속 블로그를 만들어야되는 이유에 대해 상기시키고 빠른 시일내에 블로그 프레임을 전부 완성시키도록 하겠다. 뭐 하나 제데로 하는 것이 없는 나에게 이 시도는 매우 큰 의미를 가지고 있고, 이 블로그를 계기로 나의 지난 과거를 되돌아봄과 앞으로의 열정을 불태워보겠다. 주로 코딩, 프로젝트내용 그리고 내 생활면에선 일기나 내 생각을 반영한 에세이, 취미생활에 대한 진행도나 내역을 적을 계획이다.","link":"/2021/01/14/%EC%B2%AB%EA%B8%80/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/01/14/hello-world/"},{"title":"Time Series Data Validation","text":"시계열데이터 모델검증하기 (Timeseries Validation)공부를하다 시간에따라 발생되는 데이터를 다룰 때 k-fold validation을 쓰게되면 모순적인 부분이 있다고 생각이 들어 찾아본 결과 사이킷런의 TimeSeriesSplit을 사용하는 방법이 있었다. 기본적으로 모델검증을 위한 절차는 다음 그림을 참조하여 설명하자면 ![validaion][pic][pic]: https://scikit-learn.org/stable/_images/grid_search_cross_validation.png출처:scikit learn훈련데이터를 모델검증을 위해 원하는 군집갯수로 나누어 또 다른 테스트 데이터와 훈련데이터로 나누어 N번 평가하는 것이다. 그래서 보통 N번의 MSE의 평균을 비교하여 가장 최적화된 모델이나 파라미터를 구하게 된다. 대표적으로 sklearn의 K-fold Validation이 있는데 이번에 공부하게 된건 TimeSeriesSplit이기 때문에 자세한 설명은 넘어가도록 한다. 여기서 의문이였던건 시계열데이터는 윗 그림과 같이 K-fold Validation을 쓰는 것이 옳지 않다는 것 같았다. split 1번부터 4번까지 테스트데이터를 기준으로 시간 측면에서 미래의 데이터를 훈련하여 현재의 데이터를 검증한다는 것이 나에게 있어서 논리오류를 범하는 것 같았다. 그래서 선택해본 것이 sklearn의 TimeseriesSplit이다.![timeseriessplit][pic1][pic1]: https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_010.png출처:scikit learn K-fold와 조금 다르게 훈련데이터를 과거의 데이터를 기준으로 축적하여 쌓아나간다는 느낌으로 검증을 하게 된다. 다음과 같이 코딩을 하게 되는데 여기서 필자는 Simple DNN을 사용하여 이미 def함수를 사용하여 model을 구축했기 때문에 사용하고자 하는 model이나 방법론을 미리 구축해놓고 이름만 바꾸어 넣으면 될 듯 하다. 또한 여기서 필자는 fold의 갯수를 4개로 지정했다. 12345678910111213141516from sklearn.model_selection import KFold, TimeSeriesSplitn_fold = 4folds = TimeSeriesSplit(n_splits=n_fold)splits = folds.split(train)for fold_n, (train_index, valid_index) in enumerate(splits): print('Fold:', fold_n+1) X_train1, X_valid1 = x_train[x_col].iloc[train_index], x_train[x_col].iloc[valid_index] y_train1, y_valid1 = y_train.iloc[train_index], y_train.iloc[valid_index] model = build_model() history = model.fit(X_train1, y_train1, validation_data=(X_valid1, y_valid1), epochs=num_epochs, batch_size=1, verbose=0) mae_history = history.history['val_mae'] all_mae_histories.append(mae_history) 이런식으로 코딩을 하게 된 후에 all_mae_histories에 MAE스코어가 담겨있기 때문에 평균 MAE를 보고 파라미터 조정 또는 성능좋은 모델을 사용하면 된다.np.mean(all_mae_histories)![graph][pic2][pic2]:(/Users/patricklee/Desktop/pic/download.png)필자는 모델이 300회부터 오버피팅(overfitting)이 된 걸 확인 할 수 있었다.","link":"/2021/01/17/21-01-17%20first/"}],"tags":[],"categories":[{"name":"-끄적끄적","slug":"끄적끄적","link":"/categories/%EB%81%84%EC%A0%81%EB%81%84%EC%A0%81/"},{"name":"M&#x2F;L","slug":"M-L","link":"/categories/M-L/"},{"name":"Validation","slug":"M-L/Validation","link":"/categories/M-L/Validation/"}]}